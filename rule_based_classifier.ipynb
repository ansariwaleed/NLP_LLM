{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "068ef793",
   "metadata": {},
   "source": [
    "It will take a text X and return a label pf \"1\" - if postive; \"-1\" for negative and \"0\" for neutral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b984b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(X:str) -> dict[str, float]:\n",
    "    features = {}\n",
    "    x_split = X.split()\n",
    "\n",
    "    #count the number of \"good words\" and \"bad words\"\n",
    "    good_words = [\"good\", \"great\", \"excellent\", \"fantastic\", \"amazing\"]\n",
    "    bad_words = [\"bad\", \"terrible\", \"awful\", \"horrible\", \"dreadful\",\"thinking\",\"worst\",\"thinks\"]\n",
    "    for x_word in x_split:\n",
    "        if x_word in good_words:\n",
    "            features[\"good_words\"] = features.get(\"good_words\", 0) + 1\n",
    "        elif x_word in bad_words:\n",
    "            features[\"bad_words\"] = features.get(\"bad_words\", 0) + 1\n",
    "            #increment the count of bad words and good words\n",
    "\n",
    "    #The \"bias\" value is always one, to allow us to assign a default weight to the bias term in a model\n",
    "    features[\"bias\"] = 1.0\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0611d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights = {\n",
    "    \"good_words\": 1,\n",
    "    \"bad_words\": -1,\n",
    "    \"bias\": 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754f8af",
   "metadata": {},
   "source": [
    "Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58ee3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xy_data(filename: str) -> tuple[list[str], list[int]]:\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            label, text = line.strip().split(\" ||| \")\n",
    "            x_data.append(text)\n",
    "            y_data.append(int(label))\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03e8d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = read_xy_data(\"./data/train.txt\")\n",
    "x_test, y_test = read_xy_data(\"./data/dev.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3913d758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
      "It 's a lovely film with lovely performances by Buy and Accorsi .\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae53cd8",
   "metadata": {},
   "source": [
    "Run the Classifier and Calcualte Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcae3d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(x: str )-> int: #taekes a string and returns an integer\n",
    "    score = 0\n",
    "    for feat_name, feat_value in extract_features(x).items():\n",
    "        score = score + feat_value * feature_weights.get(feat_name, 0)\n",
    "    if score > 0:\n",
    "        return 1\n",
    "    elif score < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0960a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_accuracy(x_data: list[str], y_data: list[int]) -> float:\n",
    "    total_number = 0\n",
    "    correct_number = 0\n",
    "    for x, y in zip(x_data, y_data):\n",
    "        y_pred = run_classifier(x)\n",
    "        total_number += 1\n",
    "        if y == y_pred:\n",
    "            correct_number += 1\n",
    "    return correct_number / float(total_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06cedb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts in test data: {1: 444, 0: 229, -1: 428}\n"
     ]
    }
   ],
   "source": [
    "label_count = {}\n",
    "for y in y_test:\n",
    "    if y not in label_count:\n",
    "        label_count[y] = 0\n",
    "    label_count[y] += 1\n",
    "print(\"Label counts in test data:\", label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ad3cffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.4408941947565543\n",
      "Test accuracy: 0.42779291553133514\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calcualte_accuracy(x_train, y_train)\n",
    "print(\"Train accuracy:\", train_accuracy)\n",
    "test_accuracy = calcualte_accuracy(x_test, y_test)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28ef80d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#barely passed the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07497e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
